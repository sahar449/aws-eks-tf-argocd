name: CI-CD Full Pipeline

on:
  workflow_dispatch:
    inputs:
      action:
        description: 'Choose action'
        required: true
        default: 'apply'
        type: choice
        options:
          - apply
          - destroy

permissions:
  id-token: write
  contents: read

env:
  aws_region: us-west-2
  terraform_version: 1.5.7
  image_tag: latest
  repo_name: eksdemo
  cluster_name: eksdemo-cluster
  vpc_name: eksdemo-vpc

jobs:
  ci_cd_pipeline:
    runs-on: ubuntu-latest
    if: ${{ github.event.inputs.action == 'apply' }}

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: ${{ env.terraform_version }}

      - name: Configure AWS credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v3
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}
          aws-region: ${{ env.aws_region }}
          role-session-name: github-actions
   
      - name: Terraform Apply ECR
        run: |
          terraform init -upgrade
          terraform apply -auto-approve -target=module.ecr

      - name: Login to ECR
        run: |
          aws ecr get-login-password --region ${{ env.aws_region }} | docker login --username AWS --password-stdin ${{ secrets.AWS_ACCOUNT_NUMBER }}.dkr.ecr.${{ env.aws_region }}.amazonaws.com

      - name: Build Docker Image
        run: |
          docker build -t ${{ secrets.AWS_ACCOUNT_NUMBER }}.dkr.ecr.${{ env.aws_region }}.amazonaws.com/${{ env.repo_name }}:${{ env.image_tag }} ./python-docker

      - name: Push Docker Image to ECR
        run: |
          docker push ${{ secrets.AWS_ACCOUNT_NUMBER }}.dkr.ecr.${{ env.aws_region }}.amazonaws.com/${{ env.repo_name }}:${{ env.image_tag }}

      - name: Terraform Apply Infrastructure
        run: |
          terraform apply -auto-approve

      - name: Update kubeconfig
        run: |
          aws eks update-kubeconfig --region ${{ env.aws_region }} --name ${{ env.cluster_name }} > /dev/null 

      - name: Patch aws-auth ConfigMap
        run: |
          cat <<EOF | kubectl apply -f -
          apiVersion: v1
          kind: ConfigMap
          metadata:
            name: aws-auth
            namespace: kube-system
          data:
            mapUsers: |
              - userarn: arn:aws:iam::${{ secrets.AWS_ACCOUNT_NUMBER }}:user/${{secrets.AWS_USER}}
                username: ${{secrets.AWS_USER}}
                groups:
                  - system:masters
          EOF

      - name: Helm Install ArgoCD
        run: |
          helm repo add argo https://argoproj.github.io/argo-helm
          helm repo update
          helm upgrade --install argocd argo/argo-cd \
            --namespace argocd \
            --create-namespace \
            --set server.service.type=LoadBalancer \
            --set server.service.annotations."service\.beta\.kubernetes\.io/aws-load-balancer-type"="classic"

      - name: Get VPC ID by Name
        run: |
          export VPC_ID=$(aws ec2 describe-vpcs \
            --filters "Name=tag:Name,Values=${{ env.vpc_name }}" \
            --query "Vpcs[0].VpcId" \
            --output text)
          echo "VPC_ID=$VPC_ID" >> $GITHUB_ENV

      - name: Install ALB Controller via Helm
        run: |
          helm repo add eks https://aws.github.io/eks-charts
          helm repo update
          helm upgrade --install aws-load-balancer-controller eks/aws-load-balancer-controller \
            --namespace kube-system \
            --create-namespace \
            --set clusterName=${{ env.cluster_name }} \
            --set region=${{ env.aws_region }} \
            --set vpcId=${{ env.VPC_ID }} \
            --set serviceAccount.create=true \
            --set serviceAccount.name=aws-load-balancer-controller \
            --set serviceAccount.annotations."eks\.amazonaws\.com/role-arn"="arn:aws:iam::${{ secrets.AWS_ACCOUNT_NUMBER }}:role/eks-lb-controller-role" \
            --set cleanupOnDelete=true
          kubectl -n kube-system rollout status deployment/aws-load-balancer-controller --timeout=2m


      - name: Install ExternalDNS via Helm
        continue-on-error: true
        run: |
          helm repo add external-dns https://kubernetes-sigs.github.io/external-dns/
          helm repo update
          helm upgrade --install external-dns external-dns/external-dns \
            --namespace kube-system \
            --create-namespace \
            --set provider=aws \
            --set region=${{ env.aws_region }} \
            --set domainFilters[0]=saharbittman.com \
            --set policy=sync \
            --set sources[0]=ingress \
            --set sources[1]=service \
            --set serviceAccount.create=true \
            --set serviceAccount.name=external-dns \
            --set serviceAccount.annotations."eks\.amazonaws\.com/role-arn"="arn:aws:iam::${{ secrets.AWS_ACCOUNT_NUMBER }}:role/eks-external-dns-role" \
            --set txtOwnerId=${{ env.cluster_name }} \
            --set cleanupOnDelete=true
      
      - name: Download and Install ArgoCD CLI
        run: |
          ARGOCD_VERSION=$(curl -s https://api.github.com/repos/argoproj/argo-cd/releases/latest | grep tag_name | cut -d '"' -f 4)
          sudo curl -sSL -o /usr/local/bin/argocd "https://github.com/argoproj/argo-cd/releases/download/$ARGOCD_VERSION/argocd-linux-amd64"
          sudo chmod +x /usr/local/bin/argocd
          argocd version --client

      - name: Login to ArgoCD and create/update app
        continue-on-error: true
        run: |
          aws eks update-kubeconfig --region ${{ env.aws_region }} --name ${{ env.cluster_name }} > /dev/null 

          ARGOCD_ADMIN_PASSWORD=$(kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath='{.data.password}' | base64 --decode)
          echo "ARGO CD Admin Password: $ARGOCD_ADMIN_PASSWORD"

          echo "‚è≥ Waiting for ArgoCD to be ready..."
          for i in {1..20}; do
            ARGOCD_SERVER=$(kubectl get svc argocd-server -n argocd -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' 2>/dev/null)

            if [[ -n "$ARGOCD_SERVER" ]]; then
              echo "Found LoadBalancer DNS: $ARGOCD_SERVER"
              if nslookup "$ARGOCD_SERVER" > /dev/null 2>&1; then
                if argocd login "$ARGOCD_SERVER" --username admin --password "$ARGOCD_ADMIN_PASSWORD" --insecure --grpc-web > /dev/null 2>&1; then
                  echo "‚úÖ Successfully logged in to ArgoCD at $ARGOCD_SERVER"
                  break
                else
                  echo "‚ö†Ô∏è ArgoCD not ready yet (login failed) - retrying..."
                fi
              else
                echo "‚ö†Ô∏è DNS not resolvable yet - retrying..."
              fi
            else
              echo "‚ö†Ô∏è LoadBalancer not assigned yet - retrying..."
            fi

            sleep 10
          done

          if ! argocd account list > /dev/null 2>&1; then
            echo "‚ùå Failed to connect to ArgoCD after waiting."
            exit 1
          fi

          argocd app create flask \
            --repo https://github.com/sahar449/aws-eks-tf-argocd.git \
            --path chart-flask \
            --dest-server https://kubernetes.default.svc \
            --helm-set app.image.repository="${{secrets.ECR_NAME}}" \
            --helm-set app.image.tag="latest" \
            --revision HEAD \
            --sync-policy automated \
            --auto-prune \
            --self-heal \
            --upsert

      - name: Verify Flask App
        run: |
          EXPECTED_RESPONSE="Hello, World from Sahar Bittman!"
          URL="https://www.saharbittman.com"

          echo "‚è≥ Waiting for Flask app to respond with expected message..."

          for i in {1..20}; do
            RESPONSE=$(curl -sk $URL)
            if [[ "$RESPONSE" == "$EXPECTED_RESPONSE" ]]; then
              echo "‚úÖ Flask app is up! Response: $RESPONSE"
              break
            else
              echo "‚ö†Ô∏è Attempt $i/20: Flask app not ready yet. Got: $RESPONSE"
            fi
            sleep 10
          done

          # Final check
          RESPONSE=$(curl -sk $URL)
          if [[ "$RESPONSE" != "$EXPECTED_RESPONSE" ]]; then
            echo "‚ùå Flask app did not respond with expected message after waiting."
            exit 1
          fi


  destroy_pipeline:
    runs-on: ubuntu-latest
    if: ${{ github.event.inputs.action == 'destroy' || failure() }}
    needs: ci_cd_pipeline

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: ${{ env.terraform_version }}

      - name: Configure AWS credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v3
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}
          aws-region: ${{ env.aws_region }}
          role-session-name: github-actions

      - name: Destroy EKS
        run: |
          aws eks update-kubeconfig --region ${{ env.aws_region }} --name ${{ env.cluster_name }} > /dev/null

          INGRESS_NAME="flask-app-ingress"
          NAMESPACE="default"

          echo "üîπ Removing Ingress finalizers..."
          kubectl get ingress $INGRESS_NAME -n $NAMESPACE -o json | jq 'del(.metadata.finalizers)' | kubectl apply -f - || true

          echo "üîπ Deleting Ingress..."
          kubectl delete ingress $INGRESS_NAME -n $NAMESPACE --ignore-not-found=true || true

          echo "üîπ Waiting for Ingress and its Service to be deleted..."
          for i in {1..30}; do
            INGRESS_EXISTS=$(kubectl get ingress $INGRESS_NAME -n $NAMESPACE --ignore-not-found)
            SERVICE_EXISTS=$(kubectl get svc $INGRESS_NAME -n $NAMESPACE --ignore-not-found)
            
            if [[ -z "$INGRESS_EXISTS" && -z "$SERVICE_EXISTS" ]]; then
              echo "‚úÖ Ingress and Service deleted successfully!"
              break
            fi

            echo "‚è≥ Waiting for Ingress/Service to be deleted... ($i/30)"
            sleep 10
          done

          echo "üîπ Cleaning ArgoCD application..."
          kubectl patch app flask -n argocd -p '{"metadata":{"finalizers":null}}' --type=merge || true
          kubectl delete applications -n argocd flask --ignore-not-found=true || true
          helm uninstall argocd -n argocd || true

          echo "üîπ Destroying EKS cluster via Terraform..."
          terraform init -upgrade
          terraform destroy -target=module.eks -auto-approve || true



      - name: Remove Security Groups from VPC
        run: |
          for sg in $(aws ec2 describe-security-groups --region ${{ env.aws_region }} \
            --query 'SecurityGroups[?GroupName!=`default`].GroupId' --output text); do
            echo "Trying to delete SG $sg"
            aws ec2 delete-security-group --region ${{ env.aws_region }} --group-id $sg || echo "Cannot delete $sg, still in use"
          done

      - name: Terraform Destroy Remaining Resources
        run: |
          terraform init -upgrade
          terraform destroy -auto-approve || true
